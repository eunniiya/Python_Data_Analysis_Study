## 📌 소득 예측 모델 만들기
- adult 데이터는 미국인의 성별, 인종, 직업, 학력 등 다양한 인적 정보를 담고 있는 인구 조사 데이터이다.
- adult 데이터를 이용해 인적 정보로 소득을 예측하는 의사결정나무 모델을 만들어보자.

> 😊 **모델을 만드는 절차**
>
> 전처리 -> 모델 만들기 -> 예측 및 성능 평가

- 먼저 adult 데이터를 불러와 구조를 살펴보자

```python
import pandas as pd
df = pd.read_csv('adult.csv')
df.info()
```
<img width="217" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/aac9167e-2507-4ccc-941b-63b094ceb5c8">

- adult 데이터는 48,842명의 정보를 담고 있으며 변수 15개로 구성된다.
- 이 중 연소득을 나타낸 income을 타겟 변수, 나머지 14개를 예측 변수로 사용해보자.

|변수명|의미|
|:---:|:---:|
|age|나이|
|workclass|근로 형태|
|fnlwgt|인구 통계 가중치|
|education|최종 학력|
|marital_status|결혼 상태|
|occupation|직종|
|relationship|가구주와의 관계|
|race|인종|
|sex|성별|
|capital_gain|자본 소득(USD)|
|capital_loss|자본 손실(USD)|
|hours_per_week|주당 근무 시간|
|native_country|출신 국가|
|income|연소득|

-------
#### ✔️ Do it! 실습 - 전처리하기
- 머신러닝 모델을 만들 때 가장 먼저 하는 작업은 모델을 만드는데 적합하도록 데이터를 가공하는 것이다.
- adult 데이터를 전처리해보자.

**1. 타겟 변수 전처리**
- 먼저 타겟 변수 income을 검토하고 전처리해보자.
- income은 조사 응답자의 연소득이 5만 달러를 초과하는지 여부를 나타낸다.

```python
df['income'].value_counts(normalize = True)
```
<img width="133" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/3e3d4940-faaa-43c6-9623-245ce299d449">

> 다음 코드의 출력 결과를 보면 연소득이 5만 달러를 초과하는 사람(> 50K)은 23.9%, 5만 달러 이하인 사람(<= 50K)은 76%이다.

- 변수의 값에 특수문자나 대소문자가 섞여 있으면 다루기 불편하므로 5만 달러 초과하면 'high', 그렇지 않으면 'low'로 값을 수정해보자

```python
import numpy as np
df['income'] = np.where(df['income'] == '>50K', 'high', 'low')
df['income'].value_counts(normaliz = True)
```
<img width="136" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/f0279725-e4ff-45d7-82c7-52a0b0c4be1d">

**2. 불필요한 변수 제거하기**
- 이름, 아이디, 주소 같은 변수는 대부분의 값이 고유값이어서 반복되는 패턴이 없고 타겟 변수와도 관련성이 없다.
- 이런 변수는 타겟 변수를 예측하는 데 도움이 되지 않고 모델링 시간만 늘리는 역할을 하므로 제거해야한다.
- 'fnlwgt'는 adult 데이터를 이용해 미국의 실제 인구를 추정할 때 사용하는 가중치이다.
- 인종, 성별, 나이 등 인구 통계 속성이 같으면 fnlwgt가 같다.
- fnlwgt는 타겟 변수를 예측하는 데 도움이 되지 않는 변수이므로 모델을 만들 때 사용하지 않도록 제거해보자.

```python
df = df.drop(columns = 'fnlwgt')
```

**3. 문자 타입 변수를 숫자 타입으로 바꾸기**
- 모델을 만드는 데 사용되는 모든 변수는 숫자 타입이어야 한다.
- df.info()의 출력 결과를 보면 Dtype이 object인 문자 타입 변수들이 있다.
- 이 변수들을 모델을 만드는 데 활용하려면 숫자 타입으로 바꿔야한다.

#### 😄 원핫 인코딩하기
- 변수의 범주가 특정 값이면 1, 그렇지 않으면 0으로 바꾸면 문자 타입 변수를 숫자 타입으로 만들 수 있다.
- 이렇게 값을 1과 0으로 바꾸는 방법을 **원핫 인코딩**이라 한다.

![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/7b4412c8-5756-4cc4-bb76-f2be0dffb200)

- df의 sex를 추출해 원핫 인코딩하는 방법을 알아보자.
- df_tmp의 sex는 'Male' 또는 'Female'로 되어있는 문자 타입 변수이다.

```python
df_tmp = df[['sex']]
df_tmp.info()
```
<img width="172" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/39b20c9b-9ac9-46a2-89f4-5b2939940d9e">

```python
df_tmp['sex'].value_counts()
```
<img width="118" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/1b61b803-e982-4242-b7e9-9217166eeb0a">

- pd.get_dummies()에 데이터 프레임을 입력하면 문자 타입 변수를 원핫 인코딩을 적용해 변환된다.

```python
# df_temp의 문자 타입 변수에 원핫 인코딩 적용
df_tmp = pd.get_get_dummies(df_tmp)
df_tmp.info()
```
<img width="196" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/9a277e84-e411-48b4-aad3-6b75c403e0c8">

> 출력 결과를 보면 sex가 사라지고 그 대신 sex_Female과 sex_Male이 만들어졌다.

- sex_Female은 sex가 Female이면 1, 그렇지 않으면 0으로 된 변수이다. 반대로 sex_Male은 반대로 sex가 Male이면 1, 그렇지 않으면 0으로 된 변수이다.

```python
df_tmp[['sex_Female','sex_Male']].head()
```

<img width="128" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/3046d475-6b40-4d6f-bc5f-d06c962c4252">

- 원핫 인코딩 후 df에 적용해보자.
- 타겟 변수인 income만 원래대로 유지하고, 모든 문자 타입 변수를 원핫 인코딩해보자.

```python
target = df['income'] # income 추출

df = df.drop(columns = 'income') # income 제거
df = pd.get_dummies(df) # 문자 타입 변수 원핫 인코딩

df['income'] = target # df에 target 삽입
df.info()
```

<img width="176" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/6b40847c-f025-4423-8c91-1541ab7d9ead">

- df.info() 출력 결과에 개별 변수의 정보가 출력되지 않은 이유는 변수가 100개 이하일 때만 변수 정보를 출력하도록 설정되어 있기 때문이다.
- df.info()에 max_cols = np.inf를 입력하면 변수의 수와 관계없이 모든 변수의 정보를 출력한다.

```python
import numpy as np
df.info(max_cols = np.inf)
```
<img width="311" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/1f3ed753-6312-4775-9f3e-0300c80a0920">

**4. 데이터 분할하기**
- 모델을 만들 때는 가지고 있는 모든 데이터를 사용하는 게 아니라 일부만 무작위로 추출해 사용해야한다.

#### 🥸 모든 데이터를 사용해 모델을 만들면 성능 평가 점수를 신뢰할 수 없다.
- 모델을 만들고 나면 모델이 타겟 변수를 얼마나 정확하게 예측하는지 알아보기 위해 성능을 평가한다.
- 그러나 모델을 만들 때 사용한 데이터를 성능을 평가할 때 그대로 다시 사용하면 평가 점수를 신뢰할 수 없게 된다.

#### 🥸 크로스 밸리데이션: 신뢰할 수 있는 성능 평가 점수를 얻는 방법
- 신뢰할 수 있는 성능 평가 점수를 얻을려면 가지고 있는 데이터에서 일부만 추출해 모델을 만들 때 사용하고, 나머지는 남겨 두었다가 성능을 평가할 때 사용해야한다.
- 데이터가 있으면 훈련용과 평가용으로 나누어 사용하는 것이다.
- 이처럼 데이터를 분할해 일부는 모델을 만들 때 사용하고 나머지는 평가할 때 사용하는 방법을 크로스 밸리데이션이라고 한다.

#### 🤠 adult 데이터 분할하기
- scikit-learn 패키지를 이용해 데이터를 트레이닝 세트와 테스트 세트로 분할해보자.
- scikit-learn은 머신러닝 모델을 만들 때 가장 많이 사용되는 패키지이다.
- sklearn.model_selection의 train_test_split()을 이용하면 데이터를 트레인이 세트와 테스트 세트로 분할할 수 있다.
- train_test_split()에는 다음과 같은 파라미터를 입력해야한다.
  - test_size: 테스트 세트의 비율, 트레이닝 세트와 테스트 세트의 비율은 보통 7:3 또는 8:2로 정한다.
  - stratify: 범주별 비율을 통일할 변수, stratify에 타겟 변수를 입력하면 트레이닝 세트와 테스트 세트에 타겟 변수의 범주별 비율이 데이터 세트마다 달라지므로 평가 결과를 신뢰하기 어렵다.
  - random_state: 난수 초깃값. train_test_split()은 난수를 이용해 데이터를 무작위로 추출하므로 함수를 실행할 때마다 추출되는 데이터가 조금씩 달라진다.
 
```python
from sklearn.model_selection import train_test_split
df_train, df_test = train_test_split(df,
                                     test_size = 0.3,          # 테스트 세트 비율
                                     stratify = df['income'],  # 타겟 변수 비율 유지
                                     random_state = 1234)      # 난수 고정
```

```python
# train
df_train.shape
>> (34189, 108)
```
```python
# test
df_test.shape
>> (14653, 108)
```

> 두 데이터 세트를 살펴보면 변수가 108개로 같고 , 행의 수는 다르다.

- 타겟 변수의 범주별 비율은 두 데이터 세트 모두 비슷하다.
- train_test_split()의 stratify에 타겟 변수를 지정했기 때문이다.

```python
# train
df_train['income'].value_counts(normalize = True)
```

<img width="128" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/3b7f88b7-d92e-4337-80de-c163764f21bf">

```python
# test
df_test['income'].value_counts(normalize = True)
```

<img width="130" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/caae9ad2-aeb4-4707-802c-726e061da42f">
