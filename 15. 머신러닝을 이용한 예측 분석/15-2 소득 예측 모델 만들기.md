## 📌 소득 예측 모델 만들기
- adult 데이터는 미국인의 성별, 인종, 직업, 학력 등 다양한 인적 정보를 담고 있는 인구 조사 데이터이다.
- adult 데이터를 이용해 인적 정보로 소득을 예측하는 의사결정나무 모델을 만들어보자.

> 😊 **모델을 만드는 절차**
>
> 전처리 -> 모델 만들기 -> 예측 및 성능 평가

- 먼저 adult 데이터를 불러와 구조를 살펴보자

```python
import pandas as pd
df = pd.read_csv('adult.csv')
df.info()
```
<img width="217" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/aac9167e-2507-4ccc-941b-63b094ceb5c8">

- adult 데이터는 48,842명의 정보를 담고 있으며 변수 15개로 구성된다.
- 이 중 연소득을 나타낸 income을 타겟 변수, 나머지 14개를 예측 변수로 사용해보자.

|변수명|의미|
|:---:|:---:|
|age|나이|
|workclass|근로 형태|
|fnlwgt|인구 통계 가중치|
|education|최종 학력|
|marital_status|결혼 상태|
|occupation|직종|
|relationship|가구주와의 관계|
|race|인종|
|sex|성별|
|capital_gain|자본 소득(USD)|
|capital_loss|자본 손실(USD)|
|hours_per_week|주당 근무 시간|
|native_country|출신 국가|
|income|연소득|

-------
#### ✔️ Do it! 실습 - 전처리하기
- 머신러닝 모델을 만들 때 가장 먼저 하는 작업은 모델을 만드는데 적합하도록 데이터를 가공하는 것이다.
- adult 데이터를 전처리해보자.

**1. 타겟 변수 전처리**
- 먼저 타겟 변수 income을 검토하고 전처리해보자.
- income은 조사 응답자의 연소득이 5만 달러를 초과하는지 여부를 나타낸다.

```python
df['income'].value_counts(normalize = True)
```
<img width="133" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/3e3d4940-faaa-43c6-9623-245ce299d449">

> 다음 코드의 출력 결과를 보면 연소득이 5만 달러를 초과하는 사람(> 50K)은 23.9%, 5만 달러 이하인 사람(<= 50K)은 76%이다.

- 변수의 값에 특수문자나 대소문자가 섞여 있으면 다루기 불편하므로 5만 달러 초과하면 'high', 그렇지 않으면 'low'로 값을 수정해보자

```python
import numpy as np
df['income'] = np.where(df['income'] == '>50K', 'high', 'low')
df['income'].value_counts(normaliz = True)
```
<img width="136" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/f0279725-e4ff-45d7-82c7-52a0b0c4be1d">

**2. 불필요한 변수 제거하기**
- 이름, 아이디, 주소 같은 변수는 대부분의 값이 고유값이어서 반복되는 패턴이 없고 타겟 변수와도 관련성이 없다.
- 이런 변수는 타겟 변수를 예측하는 데 도움이 되지 않고 모델링 시간만 늘리는 역할을 하므로 제거해야한다.
- 'fnlwgt'는 adult 데이터를 이용해 미국의 실제 인구를 추정할 때 사용하는 가중치이다.
- 인종, 성별, 나이 등 인구 통계 속성이 같으면 fnlwgt가 같다.
- fnlwgt는 타겟 변수를 예측하는 데 도움이 되지 않는 변수이므로 모델을 만들 때 사용하지 않도록 제거해보자.

```python
df = df.drop(columns = 'fnlwgt')
```

**3. 문자 타입 변수를 숫자 타입으로 바꾸기**
- 모델을 만드는 데 사용되는 모든 변수는 숫자 타입이어야 한다.
- df.info()의 출력 결과를 보면 Dtype이 object인 문자 타입 변수들이 있다.
- 이 변수들을 모델을 만드는 데 활용하려면 숫자 타입으로 바꿔야한다.

#### 😄 원핫 인코딩하기
- 변수의 범주가 특정 값이면 1, 그렇지 않으면 0으로 바꾸면 문자 타입 변수를 숫자 타입으로 만들 수 있다.
- 이렇게 값을 1과 0으로 바꾸는 방법을 **원핫 인코딩**이라 한다.

![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/7b4412c8-5756-4cc4-bb76-f2be0dffb200)

- df의 sex를 추출해 원핫 인코딩하는 방법을 알아보자.
- df_tmp의 sex는 'Male' 또는 'Female'로 되어있는 문자 타입 변수이다.

```python
df_tmp = df[['sex']]
df_tmp.info()
```
<img width="172" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/39b20c9b-9ac9-46a2-89f4-5b2939940d9e">

```python
df_tmp['sex'].value_counts()
```
<img width="118" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/1b61b803-e982-4242-b7e9-9217166eeb0a">

- pd.get_dummies()에 데이터 프레임을 입력하면 문자 타입 변수를 원핫 인코딩을 적용해 변환된다.

```python
# df_temp의 문자 타입 변수에 원핫 인코딩 적용
df_tmp = pd.get_get_dummies(df_tmp)
df_tmp.info()
```
<img width="196" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/9a277e84-e411-48b4-aad3-6b75c403e0c8">

> 출력 결과를 보면 sex가 사라지고 그 대신 sex_Female과 sex_Male이 만들어졌다.

- sex_Female은 sex가 Female이면 1, 그렇지 않으면 0으로 된 변수이다. 반대로 sex_Male은 반대로 sex가 Male이면 1, 그렇지 않으면 0으로 된 변수이다.

```python
df_tmp[['sex_Female','sex_Male']].head()
```

<img width="128" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/3046d475-6b40-4d6f-bc5f-d06c962c4252">

- 원핫 인코딩 후 df에 적용해보자.
- 타겟 변수인 income만 원래대로 유지하고, 모든 문자 타입 변수를 원핫 인코딩해보자.

```python
target = df['income'] # income 추출

df = df.drop(columns = 'income') # income 제거
df = pd.get_dummies(df) # 문자 타입 변수 원핫 인코딩

df['income'] = target # df에 target 삽입
df.info()
```

<img width="176" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/6b40847c-f025-4423-8c91-1541ab7d9ead">

- df.info() 출력 결과에 개별 변수의 정보가 출력되지 않은 이유는 변수가 100개 이하일 때만 변수 정보를 출력하도록 설정되어 있기 때문이다.
- df.info()에 max_cols = np.inf를 입력하면 변수의 수와 관계없이 모든 변수의 정보를 출력한다.

```python
import numpy as np
df.info(max_cols = np.inf)
```
<img width="311" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/1f3ed753-6312-4775-9f3e-0300c80a0920">

**4. 데이터 분할하기**
- 모델을 만들 때는 가지고 있는 모든 데이터를 사용하는 게 아니라 일부만 무작위로 추출해 사용해야한다.

#### 🥸 모든 데이터를 사용해 모델을 만들면 성능 평가 점수를 신뢰할 수 없다.
- 모델을 만들고 나면 모델이 타겟 변수를 얼마나 정확하게 예측하는지 알아보기 위해 성능을 평가한다.
- 그러나 모델을 만들 때 사용한 데이터를 성능을 평가할 때 그대로 다시 사용하면 평가 점수를 신뢰할 수 없게 된다.

#### 🥸 크로스 밸리데이션: 신뢰할 수 있는 성능 평가 점수를 얻는 방법
- 신뢰할 수 있는 성능 평가 점수를 얻을려면 가지고 있는 데이터에서 일부만 추출해 모델을 만들 때 사용하고, 나머지는 남겨 두었다가 성능을 평가할 때 사용해야한다.
- 데이터가 있으면 훈련용과 평가용으로 나누어 사용하는 것이다.
- 이처럼 데이터를 분할해 일부는 모델을 만들 때 사용하고 나머지는 평가할 때 사용하는 방법을 크로스 밸리데이션이라고 한다.

#### 🤠 adult 데이터 분할하기
- scikit-learn 패키지를 이용해 데이터를 트레이닝 세트와 테스트 세트로 분할해보자.
- scikit-learn은 머신러닝 모델을 만들 때 가장 많이 사용되는 패키지이다.
- sklearn.model_selection의 train_test_split()을 이용하면 데이터를 트레인이 세트와 테스트 세트로 분할할 수 있다.
- train_test_split()에는 다음과 같은 파라미터를 입력해야한다.
  - test_size: 테스트 세트의 비율, 트레이닝 세트와 테스트 세트의 비율은 보통 7:3 또는 8:2로 정한다.
  - stratify: 범주별 비율을 통일할 변수, stratify에 타겟 변수를 입력하면 트레이닝 세트와 테스트 세트에 타겟 변수의 범주별 비율이 데이터 세트마다 달라지므로 평가 결과를 신뢰하기 어렵다.
  - random_state: 난수 초깃값. train_test_split()은 난수를 이용해 데이터를 무작위로 추출하므로 함수를 실행할 때마다 추출되는 데이터가 조금씩 달라진다.
 
```python
from sklearn.model_selection import train_test_split
df_train, df_test = train_test_split(df,
                                     test_size = 0.3,          # 테스트 세트 비율
                                     stratify = df['income'],  # 타겟 변수 비율 유지
                                     random_state = 1234)      # 난수 고정
```

```python
# train
df_train.shape
>> (34189, 108)
```
```python
# test
df_test.shape
>> (14653, 108)
```

> 두 데이터 세트를 살펴보면 변수가 108개로 같고 , 행의 수는 다르다.

- 타겟 변수의 범주별 비율은 두 데이터 세트 모두 비슷하다.
- train_test_split()의 stratify에 타겟 변수를 지정했기 때문이다.

```python
# train
df_train['income'].value_counts(normalize = True)
```

<img width="128" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/3b7f88b7-d92e-4337-80de-c163764f21bf">

```python
# test
df_test['income'].value_counts(normalize = True)
```

<img width="130" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/caae9ad2-aeb4-4707-802c-726e061da42f">

-------
#### ✔️ Do it! 실습 - 의사결정나무 모델 만들기
- 전처리를 완료했으므로 이제 모델을 만들어보자.
- 모델을 만들때는 df_train을 사용한다.
- df_test는 마지막에 모델을 평가할 때 사용한다.

#### 🤓 모델 설정하기
- sklearn의 tree.DecisionTreeClassifier() 클래스를 이용하면 의사결정나무 모델을 만들 수 있다.
- 먼저 모델을 만드는 데 사용할 clf를 만들어보자.
- tree.DecisionTreeClassifier()에는 다음과 같은 파라미터를 입력한다.
    - random_state: 난수 초깃값. 변수 선택 과정에서 난수를 이용하기 때문에 코드를 실행할 때마다 결과가 조금씩 달라진다.
    - max_depth: 나무의 깊이. 노드를 최대 몇 번까지 분할할지 정한다. 숫자가 클수록 노드를 여러 번 분할해 복잡한 모델을 만든다.

```python
from sklearn import tree
clf = tree.DecisionTreeClassifier(random_state = 1234,  # 난수 고정
                                  max_depth = 3)        # 나무 깊이
```

#### 🤓 모델 만들기
- 앞에서 만든 clf()를 이용해 모델을 만들어보자.
- 먼저 df_train에서 예측 변수와 타겟 변수를 각각 추출해 데이터 프레임을 만든다.
- clf.fit()의 X에는 예측 변수, y에는 타겟 변수를 입력한다.

```python
train_x = df_train.drop(columns = 'income') # 예측 변수 추출
train_y = df_train['income']                # 타겟 변수 추출

model = clf.fit(X = train_x , y = train_y)  # 모델 만들기
```

-------
#### ✔️ Do it! 실습 - 모델 구조 살펴보기
- 완성된 모델을 그래프로 만들어 구조를 살펴보자.
- tree.plot_tree()을 이용하면 모델을 시각화할 수 있다.

```python
import matplotlib.pyplot as plt
plt.rcParams.update({'figure.dpi'     : '100',    # 해상도 설정
                     'figure.figsize' : [12,8]})  # 그래프 크기 설정

tree.plot_tree(model);                            # 그래프 출력 
```

![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/aca7cf83-7273-4c63-a75d-2ad85992e92f)

- tree.plot_tree()에 몇 가지 파라미터를 추가해 그래프를 보기 좋게 수정해보자.

```python
tree.plot_tree(model,
               feature_names = train_x.columns, # 예측 변수명
               class_names = ['high', 'low'],   # 타겟 변수 클래스, 알파벳 순
               proportion = True,               # 비율 표기
               filled = True,                   # 색칠
               rounded = True,                  # 둥근 테두리
               impurity = False,                # 불순도 표시
               label = 'root' ,                 # label 표시 위치
               fontsize = 10);                  # 글자 크기
```
![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/3820cdd3-e74f-47eb-886c-677d316303a1)

#### 📰 노드의 값
- 그래프에서 가장 위에 있는 첫 번째 노드를 이용해 그래프를 해석하는 방법을 알아보자.

<img width="644" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/027c0452-0694-4b0b-9eb4-f7975e45f375">

1. 전체 데이터의 몇 퍼센트가 해당 노드로 분류되었는지 나타낸다. 첫 번째 노드는 아직 한번도 나뉘지 않았으므로 데이터의 100%가 이 노드에 속한다.
2. 타겟 변수의 클래스별 비율은을 알파벳순으로 나타낸다. 타겟 변수 income의 'high'와 'low'중 'high'가 알파벳순으로 우선하므로 'high','low'순으로 비율이 표시되어있다.
3. 0.5를 기준으로 타겟 변수의 두 클래스 중 어느 쪽이 더 많은 지 나타낸다. 'high'가 23.9%, 'low'가 76.1%로 'low'가 더 많으므로 'low'가 표시되었다.
4. 노드를 분리할 때 사용할 기준을 나타낸다. 이 기준을 충족하는 데이터는 왼쪽, 충분하지 않다면 오른쪽 노드로 가게 된다.
4-1. marital_status_Married-civ-spouse는 원핫 인코딩으로 만들어진 변수로 기혼이면 1, 비혼이면 0으로 되어있다. 따라서 비혼이면 변수의 값이 0이므로 'marital_status_Married-civ-spouse <= 0.5(비혼)' 조건을 만족하므로 왼쪽 노드로 내려가게되고, 기혼이면 1이 0.5보다 크므로 오른쪽 노드로 내려간다.

#### ⬅️ 왼쪽 노드
- 첫 번째 노드의 조건에 따라 나뉘어진 두 번째 단계의 왼쪽 노드를 해석해보자.

<img width="103" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/7eb35a31-7578-40fe-a524-ca53103ca871">

> 첫번째 노드의 조건인 'marital_status_Married-civ-spouse <= 0.5(비혼)' 을 충족한 비혼자가 이 노드에 할당된다.
>
> 비혼자는 전체의 54.2%를 차지한다.
>
> 비혼자의 income은 'high' 6.4%, 'low' 93.6%로 'low'가 더 많다.
>
> 다음으로 노드를 나누는 기준은 'capital_gain <= 7073.5'이다.

#### ➡️ 오른쪽 노드
- 첫 번째 노드의 조건에 따라 나뉘어진 두 번째 단계의 오른쪽 노드를 해석해보자.

<img width="106" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/46647816-298c-4627-b6f4-f8e89cdda5e6">

> 첫 번째 노드의 조건인 'marital_status_Married-civ-spouse <= 0.5(비혼)' 을 충족하지 않은 기혼자가 이 노드에 할당된다.
>
> 기혼자는 전체의 45.8%를 차지한다.
>
> 기혼자의 income은 'high' 44.7% , 'low' 55.3%으로 'low'가 더 많다.
>
> 다음으로 노드를 나누는 기준은 'education_num <= 12.5'이다.


#### 🌈 노드의 색

**노드의 색깔**
- 노드의 색깔은 우세한 타겟 변수의 클래스에 따라 정해진다.
- 그래프를 보면 'high'의 비율이 높은 노드는 주황색, 'low'의 비율이 높은 노드는 파란색 계열로 표현되어있다.

**노드의 색 농도**
- 노드의 색 농도는 '한 클래스의 구성 비율이 우세한 정도'를 나타낸다.
- 한 클래스의 비율이 다른 클래스보다 높을수록 농도가 진하고, 두 클래스의 비율이 비슷할수록 농도가 연하다.


-------
#### ✔️ Do it! 실습 - 모델을 이용해 예측하기
- 앞에서 만든 모델을 활용해 새 데이터의 타겟 변수를 예측하는 방법을 알아보자.
- 모델을 만들 때 사용하지 않은 df_test에서 예측 변수와 타겟 변수를 각각 추출해보자.

```python
test_x = df_test.drop(columns = 'income') # 예측 변수 추출
test_y = df_test['income']                # 타겟 변수 추출
```

- model.predict()를 이용하면 모델을 이용해 새 데이터의 타겟 변수 값을 예측할 수 있다.
- model.predict()에 test_x를 입력해 타겟 변수 예측값을 구한 다음 df_test['pred']에 할당해보자.

```python
# 예측값 구하기
df_test['pred'] = model.predict(test_x)
df_test
```

<img width="925" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/384b5e43-2f09-4597-b3fd-8894475e82f9">4

> income과 pred의 값을 보면 모델의 예측이 맞았는지 알 수 있다.
>
> 두 변수의 값이 같으면 예측이 맞은 것이고, 두 변수의 값이 다르면 예측이 틀린 것.


-------
#### ✔️ Do it! 실습 - 성능 평가하기
- 예측값을 실제값과 대조해 예측이 얼마나 잘 맞았는지 모델의 성능을 평가해보자.
- 성능 평가 지표는 종류가 다양하고 특징이 서로 달라서 어떤 지표가 높더라도 다른 지표는 낮을 수 있다.


**confusion matrix 만들기**
- 모델이 예측한 값 중 맞은 경우와 틀린 경우의 빈도를 나타낸 **컨퓨전 매트릭스**를 만들어보자.
- sklearn.matrics의 confusion_matrix()를 이용하면 컨퓨전 매트릭스를 만들 수 있다.
- confusion_matrix()에는 다음 파라미터를 입력해보자.
   - y_true : 타겟 변수
   - y_pred : 예측 변수
   - labels : 클래스 배치 순서
 
```python
from sklearn.metrics import confusion_matrix
conf_mat = confusion_matrix(y_true = df_test['income'],  # 실제 값
                            y_pred = df_test['pred'],    # 예측 값
                            labels = ['high', 'low'])    # 클래스 배치 순서
conf_mat
```

<img width="157" alt="image" src="https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/8c5da242-fd9a-412b-9288-eb8d6f0537d9">

- sklearn.metrics의 ConfusionMatrixDisplay()를 이용해 컨퓨전 매트릭스로 히트맵을 만들어 값을 살펴보자.
- 히트맵은 격자 위에 값을 표시하고 값이 클수록 셀의 색 농도를 진하게 표현한 그래프이다.

```python
pit.rcParams.update(pit.rcParamsDefault)  # 그래프 설정 되돌리기

from sklearn.metrics import ConfusionMatrixDisplay
p = ConfusionMatrixDisplay(confusion_matrix = conf_mat,      # 컨퓨전 매트릭스
                           display_labels = ('high', 'low')) # 타겟 변수 클래스명

p.plot(cmap = 'Blues')                                        # 컬러맵 적용해 출력
```

![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/9b3f5732-fd8a-4160-bb4a-b365629e1ec3)

#### 💻 confusion matrix 해석하기
- 컨퓨전 매트릭스 행은 실제 빈도를 의미한다.
- 첫 번째 행은 income이 실제로 high인 사람, 두 번째 행은 실제로 low인 사람을 나타낸다.
- 열은 모델이 예측한 빈도를 의미한다. 첫 번째 열은 모델이 high로 예측한 사람, 두 번째 열은 low로 예측한 사람을 나타낸다.
- 컨퓨전 매트릭스를 보면 예측이 맞은 빈도와 틀린 빈도를 나타낸다. 행과 열의 레이블이 같은 왼쪽 대각선의 두 셀은 예측이 맞은 빈도를 나타낸다.
- 반대로 레이블이 서로 다른 오른쪽 대각선의 두 셀은 예측이 맞은 빈도를 나타낸다.

**첫 번째 열의 값**
- 모델이 2,383명(1,801 + 582)을 high로 예측했다.
- 이 중 실제로 high인 사람은 1,801명이다(정답).
- 이 중 실제로 low인 사람은 582명이다(오답).

**두 번째 열의 값**
- 모델이 12,270명(1,705 + 10,565)을 low로 예측했다.
- 이 중 실제로 low인 사람은 10,565명이다(정답).
- 이 중 실제로 high인 사람은 1,705명이다(오답).

**컨퓨전 매트릭스의 셀 이름**

![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/9494262e-000b-4ae1-92a2-5cb7edfd91dc)

> 컨퓨전 매트릭스의 각 셀은 다음과 같은 단어로 표현한다.
>
> 정답 여부(True/False): 모델의 예측값이 실제값과 일치하면 True, 일치하지 않으면 False
>
> 예측 클래스(Positive/Negative): 타겟 변수의 클래스 중 모델이 예측하고자 하는 관심 클래스는 Positive, 그 반대는 Negative.
>
> 모델의 목적이 고소득자를 찾아내는 것이므로 income이 high이면 Positive, low면 Negative가 된다.


#### 성능 평가 지표 구하기
- 성능 평가 지표를 구하면 모델의 예측이 얼마나 정확한지 알 수 있다.

**1. Accuracy**
- accuracy(정확도)는 모델이 '예측해서 맞춘 비율'을 의미한다.
- 컨퓨전 매트릭스 전체 셀 합계에서 왼쪽 대각선의 셀의 합계가 차지하는 비율이 accuracy이다.
- accuracy는 앞에서 만든 conf_mat을 이용해 직접 계산할 수도 있지만 sklearn.metrics의 accuracy_score()를 이용하면 구할 수도 있다.
  
![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/5cfd5627-02c6-4893-83ca-2172e2a8edaa)

```python
import sklearn.metrics as metrics
metrics.accuracy_score(y_true = df_test['income'], # 실제값
                       y_pred = df_test['pred'])   # 예측값
>> 0.8439227461953184
```

> 정확도가 약 84.3%라는 것을 알 수 있다.

**2. Precision**
- precision(정밀도)은 모델이 '관심 클래스를 예측해서 맞춘 비율'을 의미한다.
- 고소득자 예측 모델에서는 모델이 income을 high로 예측한 사람 중에서 실제로 high인 사람의 비율이 precision이다.
- Ex> 당뇨병 예측 모델이라면 모델이 발병으로 예측한 사람 중에서 실제 발병한 사람의 비율이 precision이다.
  
![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/2101b982-6a56-4ca3-a4be-ca66c7ecd1ed)

```python
metrics.precision_score(y_true = df_test['income'], # 실제값
                        y_pred = df_test['pred'],   # 예측값
                        pos_label = 'high')         # 관심 클래스
>> 0.7557700377675199
```

> 모델의 precision이 75.5%이며, income을 high로 예측한 사람 중에서 75.5%가 실제로 high이고, 나머지 24.5%는 실제로는 low인데 high로 잘못 분류한 것이다.

**3. Recall**
- recall(재현율)은 모델이 '실제 데이터에서 관심 클래스를 찾아낸 비율'을 의미한다.
- 고소득자 예측 모델에서는 income이 실제로 high인 사람 중에서 모델이 high로 예측해서 찾아 낸 사람의 비율이 recall이다.
- Ex> 당뇨병 예측 모델이라면 실제 당뇨병 발병자 중에서 모델이 발병으로 예측해서 찾아낸 비율이 recall이다.

![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/5db565b1-09b7-4ce9-8341-0d7ed9cfb911)

```python
metrics.recall_score(y_true = df_test['income'], # 실제값
                     y_pred = df_test['pred'],   # 예측값
                     pos_label = 'high')         # 관심 클래스
>> 0.5136908157444381
```

> 모델의 recall이 51.3%이며, income이 high인 사람 중에서 51.3%를 모델이 high로 맞게 예측해서 찾아냈고, 나머지 48.7%는 low으로 잘못 예측해서 놓친 것이다.

**4. F1 score**
- recall과 precision이 모두 중요할 때는 recal과 precision의 크기를 함께 반영한 F1 score를 사용한다.
- F1 score는 recall과 precision의 조화평균으로, 0~1 사이의 값을 지니며 성능이 좋을수록 1에 가까운 값이 된다.
- recall과 precision을 곱해서 구하기 때문에 둘 중 하나라도 0이면 0이된다.

> 🍯 F1 score은 accuracy와 달리 타겟 변수의 클래스가 불균형해도 모델의 성능을 잘 표현한다.

```python
metrics.f1_score(y_true = df_test['income'], # 실제값
                 y_pred = df_test['pred'],   # 예측값
                 pos_label = 'high')         # 관심 클래스
>> 0.6116488368143997
```

#### 어떤 성능 평가 지표를 사용해야 할까?
- 성능 평가 지표는 특징이 서로 달라 어떤 지표가 높더라도 다른 지표는 낮을 수 있다.
- accuracy는 모델의 일반적인 성능을 나타내므로 항상 살펴봐야한다.
- precision과 recall 중 한 가지 이상을 함께 살펴봐야한다.
    - precision : 관심 클래스가 분명할 때
        - 모델을 사용하는 목적이 타겟 변수의 클래스 중에서 관심을 두는 한쪽 클래스를 정확하게 예측하는 것이라면, precision 기준으로 성능을 평가해야한다.
        - Ex> 고소득자를 예측해 고가의 제품을 홍보한다면 모델이 고소득자로 예측했을 때 얼마나 잘 맞는지 살펴봐야하므로 precision을 기준으로 평가해야한다.   
    - recall : 관심 클래스를 최대한 많이 찾아내야 할 때
        - 모델을 사용하는 목적이 관심 클래스를 최대한 많이 찾아내는 것이라면 recall 기준으로 성능을 평가해야한다.
        - Ex> 전염병에 감염된 사람을 최대한 많이 찾아내 격리해야 한다면, 실제로 전염병에 감염된 사람들 중에서 몇 퍼센트를 감염된 것으로 예측하는지 살펴봐야 하므로 recall을 기준으로 평가한다.


![image](https://github.com/sm9199/Python_Data_Analysis_Study/assets/128019851/9792c27a-936e-4ae1-91b4-11b1b874a503)
